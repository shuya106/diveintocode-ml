{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint アンサンブル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"/Users/morishuuya/Desktop/dataset/kaggle/HousePrice/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "t = train_data.loc[:, \"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】ブレンディングのスクラッチ実装\n",
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1回目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "dt = DecisionTreeRegressor()\n",
    "svr = SVR(gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, t_train)\n",
    "dt.fit(X_train, t_train)\n",
    "svr.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr = lr.predict(X_test)\n",
    "y_dt = dt.predict(X_test)\n",
    "y_svr = svr.predict(X_test)\n",
    "blending_1 = (y_lr + y_dt + y_svr) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      " 2490336490.8824496\n",
      "DecisionTree\n",
      " 2894135253.592466\n",
      "SVR\n",
      " 7222329801.952959\n",
      "Blend\n",
      " 2549034230.212108\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression\\n\",mean_squared_error(t_test, y_lr))\n",
    "print(\"DecisionTree\\n\", mean_squared_error(t_test, y_dt))\n",
    "print(\"SVR\\n\", mean_squared_error(t_test, y_svr))\n",
    "print(\"Blend\\n\",mean_squared_error(t_test, blending_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2回目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LinearRegression(normalize = True)\n",
    "dt2 = DecisionTreeRegressor(max_depth=5)\n",
    "svr2 = SVR(gamma=\"scale\", kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2.fit(X_train, t_train)\n",
    "dt2.fit(X_train, t_train)\n",
    "svr2.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr2 = lr2.predict(X_test)\n",
    "y_dt2 = dt2.predict(X_test)\n",
    "y_svr2 = svr2.predict(X_test)\n",
    "blending_2 = ((y_lr2) + (y_dt2) + (y_svr2)) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2490336490.8824506\n",
      "2201063572.6127987\n",
      "2515649538.6875553\n",
      "2086003299.5508206\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(t_test, y_lr2))\n",
    "print(mean_squared_error(t_test, y_dt2))\n",
    "print(mean_squared_error(t_test, y_svr2))\n",
    "print(mean_squared_error(t_test, blending_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3回目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3_sc = LinearRegression()\n",
    "dt3_sc = DecisionTreeRegressor(max_depth=3)\n",
    "svr3_sc = SVR(gamma=\"scale\", kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3 = LinearRegression()\n",
    "dt3 = DecisionTreeRegressor(max_depth=3)\n",
    "svr3 = SVR(gamma=\"scale\", kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr3_sc.fit(X_train_sc, t_train)\n",
    "dt3_sc.fit(X_train_sc, t_train)\n",
    "svr3_sc.fit(X_train_sc, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr3.fit(X_train, t_train)\n",
    "dt3.fit(X_train, t_train)\n",
    "svr3.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr3_sc = lr3_sc.predict(X_test) \n",
    "y_dt3_sc = dt3_sc.predict(X_test) \n",
    "y_svr3_sc = svr3_sc.predict(X_test)\n",
    "\n",
    "blending_3 = ((y_lr3_sc*0.0001) + (y_dt3_sc*0.9) + (y_svr3_sc*0.0009)) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9734662534743764e+16\n",
      "68950911460.19217\n",
      "5360243488764.264\n",
      "8930109409.286076\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(t_test, y_lr3_sc))\n",
    "print(mean_squared_error(t_test, y_dt3_sc))\n",
    "print(mean_squared_error(t_test, y_svr3_sc))\n",
    "\n",
    "print(mean_squared_error(t_test, blending_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ブレンディングし、重みをつけると数値が下がった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】バギングのスクラッチ実装\n",
    "バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b, X_test_b, t_train_b, t_test_b = train_test_split(X, t, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b_1 = X_train_b.iloc[:292, :]\n",
    "t_train_b_1 = t_train_b.iloc[:292]\n",
    "\n",
    "X_train_b_2 = X_train_b.iloc[292:584 , :]\n",
    "t_train_b_2 = t_train_b.iloc[292:584]\n",
    "\n",
    "X_train_b_3 = X_train_b.iloc[584:876 , :]\n",
    "t_train_b_3 = t_train_b.iloc[584:876]\n",
    "\n",
    "X_train_b_4 = X_train_b.iloc[876:1168 , :]\n",
    "t_train_b_4 = t_train_b.iloc[876:1168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_b_1 = DecisionTreeRegressor(max_depth=5)\n",
    "dt_b_2 = DecisionTreeRegressor(max_depth=5)\n",
    "dt_b_3 = DecisionTreeRegressor(max_depth=5)\n",
    "dt_b_4 = DecisionTreeRegressor(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_b_1.fit(X_train_b_1, t_train_b_1)\n",
    "dt_b_2.fit(X_train_b_2, t_train_b_2)\n",
    "dt_b_3.fit(X_train_b_3, t_train_b_3)\n",
    "dt_b_4.fit(X_train_b_4, t_train_b_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dt_b_1 = dt_b_1.predict(X_test_b)\n",
    "y_dt_b_2 = dt_b_2.predict(X_test_b)\n",
    "y_dt_b_3 = dt_b_3.predict(X_test_b)\n",
    "y_dt_b_4 = dt_b_4.predict(X_test_b)\n",
    "\n",
    "baging_1 = (y_dt_b_1+y_dt_b_2+y_dt_b_3+y_dt_b_4) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1677612420.788353\n",
      "2357848369.7927437\n",
      "1821633571.3817184\n",
      "2078780255.6058931\n",
      "1374581904.5114648\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(t_test_b, y_dt_b_1))\n",
    "print(mean_squared_error(t_test_b, y_dt_b_2))\n",
    "print(mean_squared_error(t_test_b, y_dt_b_3))\n",
    "print(mean_squared_error(t_test_b, y_dt_b_4))\n",
    "\n",
    "print(mean_squared_error(t_test_b, baging_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バギングすると数値が下がった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】スタッキングのスクラッチ実装\n",
    "スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習パート　1回目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データを分割しデータセットを3つ作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train.iloc[:389, :].values\n",
    "t_train_1 =  t_train.iloc[:389].values\n",
    "\n",
    "X_train_2 = X_train.iloc[389:778, :].values\n",
    "t_train_2 =  t_train.iloc[389:778].values\n",
    "\n",
    "X_train_3 = X_train.iloc[778:, :].values\n",
    "t_train_3 =  t_train.iloc[778:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_1_x = np.concatenate([X_train_2, X_train_3], axis=0)\n",
    "train_dataset_1_t = np.concatenate([t_train_2, t_train_3], axis=0)\n",
    "\n",
    "train_dataset_2_x = np.concatenate([X_train_1, X_train_3], axis=0)\n",
    "train_dataset_2_t = np.concatenate([t_train_1, t_train_3], axis=0)\n",
    "\n",
    "train_dataset_3_x = np.concatenate([X_train_1, X_train_2], axis=0)\n",
    "train_dataset_3_t = np.concatenate([t_train_1, t_train_2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1回目の学習、推定、ブレンドデータの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTR_1 = DecisionTreeRegressor(max_depth=5)\n",
    "DTR_2 = DecisionTreeRegressor(max_depth=5)\n",
    "DTR_3 = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "DTR_1.fit(train_dataset_1_x, train_dataset_1_t)\n",
    "DTR_2.fit(train_dataset_2_x, train_dataset_2_t)\n",
    "DTR_3.fit(train_dataset_3_x, train_dataset_3_t)\n",
    "\n",
    "y_DTR_1 = DTR_1.predict(X_train_1)\n",
    "y_DTR_2 = DTR_2.predict(X_train_2)\n",
    "y_DTR_3 = DTR_3.predict(X_train_3)\n",
    "\n",
    "DTR_blend_data = np.concatenate([y_DTR_1, y_DTR_2, y_DTR_3], axis=0)\n",
    "DTR_blend_data .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVR_1 = SVR(gamma=\"scale\")\n",
    "SVR_2 = SVR(gamma=\"scale\")\n",
    "SVR_3 = SVR(gamma=\"scale\")\n",
    "\n",
    "SVR_1.fit(train_dataset_1_x, train_dataset_1_t)\n",
    "SVR_2.fit(train_dataset_2_x, train_dataset_2_t)\n",
    "SVR_3.fit(train_dataset_3_x, train_dataset_3_t)\n",
    "\n",
    "y_SVR_1 = SVR_1.predict(X_train_1)\n",
    "y_SVR_2 = SVR_2.predict(X_train_2)\n",
    "y_SVR_3 = SVR_3.predict(X_train_3)\n",
    "\n",
    "SVR_blend_data = np.concatenate([y_SVR_1, y_SVR_2, y_SVR_3], axis=0)\n",
    "SVR_blend_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTR_SVR_blend = np.stack([DTR_blend_data , SVR_blend_data], 1)\n",
    "DTR_SVR_blend.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習パート　2回目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データを分割しデータセットを3つ作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTSVR_train_1 = DTR_SVR_blend[:389, :]\n",
    "DTSVR_train_2 = DTR_SVR_blend[389:778, :]\n",
    "DTSVR_train_3 = DTR_SVR_blend[778:, :]\n",
    "\n",
    "train_dataset_2_1_x = np.concatenate([DTSVR_train_2, DTSVR_train_3], axis=0)\n",
    "train_dataset_2_2_x = np.concatenate([DTSVR_train_1, DTSVR_train_3], axis=0)\n",
    "train_dataset_2_3_x = np.concatenate([DTSVR_train_1, DTSVR_train_2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1回目の学習、推定、ブレンドデータの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTR_2_1 = DecisionTreeRegressor(max_depth=5)\n",
    "DTR_2_2 = DecisionTreeRegressor(max_depth=5)\n",
    "DTR_2_3 = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "DTR_2_1.fit(train_dataset_2_1_x, train_dataset_1_t)\n",
    "DTR_2_2.fit(train_dataset_2_2_x, train_dataset_2_t)\n",
    "DTR_2_3.fit(train_dataset_2_3_x, train_dataset_3_t)\n",
    "\n",
    "y_DTR_2_1 = DTR_2_1.predict(X_train_1)\n",
    "y_DTR_2_2 = DTR_2_2.predict(X_train_2)\n",
    "y_DTR_2_3 = DTR_2_3.predict(X_train_3)\n",
    "\n",
    "DTR_blend_data_2 = np.concatenate([y_DTR_2_1, y_DTR_2_2, y_DTR_2_3], axis=0)\n",
    "DTR_blend_data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVR_2_1 = SVR(gamma=\"scale\")\n",
    "SVR_2_2 = SVR(gamma=\"scale\")\n",
    "SVR_2_3 = SVR(gamma=\"scale\")\n",
    "\n",
    "SVR_2_1.fit(train_dataset_2_1_x, train_dataset_1_t)\n",
    "SVR_2_2.fit(train_dataset_2_2_x, train_dataset_2_t)\n",
    "SVR_2_3.fit(train_dataset_2_3_x, train_dataset_3_t)\n",
    "\n",
    "y_SVR_2_1 = SVR_2_1.predict(X_train_1)\n",
    "y_SVR_2_2 = SVR_2_2.predict(X_train_2)\n",
    "y_SVR_2_3 = SVR_2_3.predict(X_train_3)\n",
    "\n",
    "SVR_blend_data_2 = np.concatenate([y_SVR_2_1, y_SVR_2_2, y_SVR_2_3], axis=0)\n",
    "SVR_blend_data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTR_SVR_blend_2 = np.stack([DTR_blend_data_2 , SVR_blend_data_2], 1)\n",
    "DTR_SVR_blend_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習パート 最終"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_SVR = SVR(gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_SVR.fit(DTR_SVR_blend_2, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推定 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推定パート　1回目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_DTR_1 = DTR_1.predict(X_test)\n",
    "y_test_DTR_2 = DTR_2.predict(X_test)\n",
    "y_test_DTR_3 = DTR_3.predict(X_test)\n",
    "\n",
    "y_test_SVR_1 = SVR_1.predict(X_test)\n",
    "y_test_SVR_2 = SVR_2.predict(X_test)\n",
    "y_test_SVR_3 = SVR_3.predict(X_test)\n",
    "\n",
    "blend_test_DTR = np.stack([y_test_DTR_1, y_test_DTR_2, y_test_DTR_3], 1)\n",
    "blend_test_DTR_av = np.average(blend_test_DTR , 1)\n",
    "blend_test_DTR_av.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_test_SVR = np.stack([y_test_SVR_1, y_test_SVR_2, y_test_SVR_3], 1)\n",
    "blend_test_SVR_av = np.average(blend_test_SVR , 1)\n",
    "blend_test_SVR_av.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_test_DTSVR = np.stack([blend_test_DTR_av, blend_test_SVR_av], 1)\n",
    "blend_test_DTSVR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推定パート　2回目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_DTR_2_1 = DTR_2_1.predict(blend_test_DTSVR)\n",
    "y_test_DTR_2_2 = DTR_2_2.predict(blend_test_DTSVR)\n",
    "y_test_DTR_2_3 = DTR_2_3.predict(blend_test_DTSVR)\n",
    "\n",
    "y_test_SVR_2_1 = SVR_2_1.predict(blend_test_DTSVR)\n",
    "y_test_SVR_2_2 = SVR_2_2.predict(blend_test_DTSVR)\n",
    "y_test_SVR_2_3 = SVR_2_3.predict(blend_test_DTSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_test_DTR_2 = np.stack([y_test_DTR_2_1, y_test_DTR_2_2, y_test_DTR_2_3], 1)\n",
    "blend_test_DTR_2_av = np.average(blend_test_DTR_2 , 1)\n",
    "blend_test_DTR_2_av.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_test_SVR_2 = np.stack([y_test_SVR_2_1, y_test_SVR_2_2, y_test_SVR_2_3], 1)\n",
    "blend_test_SVR_2_av = np.average(blend_test_SVR_2 , 1)\n",
    "blend_test_SVR_2_av.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 2)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_test_DTSVR_2 = np.stack([blend_test_DTR_2_av, blend_test_SVR_2_av], 1)\n",
    "blend_test_DTSVR_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推定　最終"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_y = last_SVR.predict(blend_test_DTSVR_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7235973955.262264\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(t_test, last_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
