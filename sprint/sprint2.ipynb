{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint課題 機械学習スクラッチ入門"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】train_test_splitのスクラッチ\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scratch_train_test_split(X, y, train_size=0.8,):\n",
    "    \"\"\"\n",
    "    検証用データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      学習データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    #ここにコードを書く\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    i = random.sample(range(len(X)), k=round(len(X)*train_size))\n",
    "    e = list(range(len(X)))\n",
    "    w = list(set(e) - set(i))\n",
    "    X_train = X_test = np.empty(X.shape[1])\n",
    "    y_train = y_test = np.empty(())\n",
    "    \n",
    "    for a in i:\n",
    "        X_train = np.vstack([X_train, X[a,:]])\n",
    "        y_train = np.vstack([y_train, y[a]])\n",
    "    for b in w:\n",
    "        X_test = np.vstack([X_test, X[b,:]])\n",
    "        y_test = np.vstack([y_test, y[b]])\n",
    "        \n",
    "    X_train = X_train[1:, :]\n",
    "    y_train = y_train[1:, :]\n",
    "    X_test = X_test[1:, :]\n",
    "    y_test = y_test[1:, :]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "iris_data[\"species\"] = data.target\n",
    "iris_data = iris_data[iris_data[\"species\"].isin([\"1\", \"2\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris = iris_data.drop(\"species\", axis=1)\n",
    "y_iris = iris_data[\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X_sample1 = np.concatenate((f0, f1))\n",
    "y_sample1 = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X_sample1 = X_sample1[random_index]\n",
    "y_sample1 = y_sample1[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample2 = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y_sample2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = scratch_train_test_split(X_iris, y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample1, X_test_sample1, y_train_sample1, y_test_sample1 = scratch_train_test_split(X_sample1, y_sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sample2, X_test_sample2, y_train_sample2, y_test_sample2 = scratch_train_test_split(X_sample2, y_sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】 分類問題を解くコードの作成\n",
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD = SGDClassifier(loss=\"log\")\n",
    "Dtree = DecisionTreeClassifier()\n",
    "Svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD.fit(X_train_iris, y_train_iris.ravel())\n",
    "Dtree.fit(X_train_iris, y_train_iris.ravel())\n",
    "Svm.fit(X_train_iris, y_train_iris.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_iris_SGD = SGD.predict(X_test_iris)\n",
    "y_iris_Dtree = Dtree.predict(X_test_iris)\n",
    "y_iris_Svm = Svm.predict(X_test_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_1 = SGDClassifier(loss=\"log\")\n",
    "Dtree_1 = DecisionTreeClassifier()\n",
    "Svm_1 = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_1.fit(X_train_sample1, y_train_sample1.ravel())\n",
    "Dtree_1.fit(X_train_sample1, y_train_sample1.ravel())\n",
    "Svm_1.fit(X_train_sample1, y_train_sample1.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample1_SGD = SGD_1.predict(X_test_sample1)\n",
    "y_sample1_Dtree = Dtree_1.predict(X_test_sample1)\n",
    "y_sampel1_Svm = Svm_1.predict(X_test_sample1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_2 = SGDClassifier(loss=\"log\")\n",
    "Dtree_2 = DecisionTreeClassifier()\n",
    "Svm_2 = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_2.fit(X_train_sample2, y_train_sample2.ravel())\n",
    "Dtree_2.fit(X_train_sample2, y_train_sample2.ravel())\n",
    "Svm_2.fit(X_train_sample2, y_train_sample2.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample2_SGD = SGD_2.predict(X_test_sample2)\n",
    "y_sample2_Dtree = Dtree_2.predict(X_test_sample2)\n",
    "y_sample2_Svm = Svm_2.predict(X_test_sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"/Users/morishuuya/Desktop/dataset/kaggle/HousePrice/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_raw.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = data[\"SalePrice\"]\n",
    "X_house = data.loc[:, [\"GrLivArea\", \"YearBuilt\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_house, X_test_house, y_train_house, y_test_house = scratch_train_test_split(X_house, Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDR = SGDRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDR.fit(X_train_house, y_train_house.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_house_SGDR = SGDR.predict(X_test_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
