{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 論文読解入門"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題\n",
    "それぞれについてJupyter Notebookにマークダウン形式で記述してください。\n",
    "\n",
    "(1) 物体検出の分野にはどういった手法が存在したか。\n",
    "\n",
    "(2) Fasterとあるが、どういった仕組みで高速化したのか。\n",
    "\n",
    "(3) One-Stageの手法とTwo-Stageの手法はどう違うのか。\n",
    "\n",
    "(4) RPNとは何か。\n",
    "\n",
    "(5) RoIプーリングとは何か。\n",
    "\n",
    "(6) Anchorのサイズはどうするのが適切か。\n",
    "\n",
    "(7) 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。\n",
    "\n",
    "(8) （アドバンス課題）Faster R-CNNよりも新しい物体検出の論文では、Faster R-CNNがどう引用されているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) 物体検出の分野にはどういった手法が存在したか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-CNN  \n",
    "参考論文  \n",
    "Rich feature hierarchies for accurate object detection and semantic segmentation  \n",
    "\n",
    "論文箇所  \n",
    "1 INTRODUCTION\n",
    "\n",
    "CNNを進化させregion with CNNとした  \n",
    "CNNだけだと位置情報がなかった\n",
    "regionとはregion　treeと呼ばれるモデルで画像を領域ごとに分解  \n",
    "↓  \n",
    "regionが持つ重みを学習  \n",
    "↓  \n",
    "とあるスキームを適応させる  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast R-CNN\n",
    "\n",
    "参考論文\n",
    "Fast R-CNN\n",
    "\n",
    "論文箇所\n",
    "1 INTRODUCTION\n",
    "\n",
    "R-CNNをさらに早くした  \n",
    "R-CNNには問題があった  \n",
    "１、様々な種類の処理を行なっていた　（SVM,bounding box reggressor)   \n",
    "２、そのため処理に時間とメモリを多く消費した  \n",
    "３、物体検出が遅かった  \n",
    "\n",
    "R-CNNは  \n",
    "画像を取り込みROIとよばれる層に畳み込み、その後FC層を経てsoftmaxとbounding box regressionに出力される  \n",
    "\n",
    "ROIとはmaxpoolingを使いfeature mapを作る  \n",
    "目的の物体の領域の範囲をmaxploolする  \n",
    "目的の物体の特徴量を整理する  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPP net\n",
    "\n",
    "論文箇所  \n",
    "Abstract\n",
    "\n",
    "“spatial pyramid pooling” 空間的ピラミッド poolingを用いた方法  \n",
    "従来のCNNでは入力画像は固定のながさでなければならなかったが、それを解決した  \n",
    "畳み込みを行い、feature mapから特手の場所を抜き出し、　固定のベクトルに変換し全結合層へ送る  \n",
    "空間的情報を維持しながらfc層へ送れる形にする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2)Fasterとあるが、どういった仕組みで高速化したのか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "論文箇所  \n",
    "4 EXPERIMENTS  \n",
    "4.1 Experiments on PASCAL VOC \n",
    "Using RPN yields a much faster detection system than using either SS or EB because of shared convolutional computations  \n",
    "\n",
    "RPNを用いた方法は畳み込み層を共有するため他の方法よりも早い  \n",
    "領域提案が従来より素早い手法を使用しているので、よりfasterである"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) One-Stageの手法とTwo-Stageの手法はどう違うのか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-stage\n",
    "参考論文  \n",
    "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks  \n",
    "論文箇所  \n",
    "4 EXPERIMENTS  \n",
    "4.1 Experiments on PASCAL VOC  \n",
    "One-Stage Detection vs. Two-Stage Proposal + De- tection.  \n",
    "The OverFeat paper [9] proposes a detection method that uses regressors and classifiers on sliding windows over convolutional feature maps. OverFeat is a one-stage, class-specific detection pipeline  \n",
    "\n",
    "one-stageは特徴量マップ場でウインドウをスライドさせながら、分類と回帰によって推定を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tow-stage\n",
    "参考論文  \n",
    "Fast Single Shot Detection and Pose Estimation  \n",
    "論文箇所  \n",
    "4 EXPERIMENTS  \n",
    "4.1 Experiments on PASCAL VOC  \n",
    "ours is a two-stage cascade consisting of class-agnostic pro- posals and class-specific detections.  \n",
    "\n",
    "領域の推定と、物体の推定を分けて行う方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) RPNとは何か"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "論文箇所  \n",
    "3 FASTER R-CNN  \n",
    "3.1 Region Proposal Networks  \n",
    "\n",
    "A Region Proposal Network (RPN) takes an image (of any size) as input and outputs a set of rectangular object proposals, each with an objectness score.3 We model this process with a fully convolutional network  \n",
    "At each sliding-window location, we simultaneously predict multiple region proposals, where the number of maximum possible proposals for each location is denoted as k. So the reg layer has 4k outputs encoding the coordinates of k boxes, and the cls layer outputs 2k scores that estimate probability of object or not object for each proposal  \n",
    "\n",
    "画像から目的の物体を認識してその部分を切り取る技術　　\n",
    "\n",
    "\n",
    "高さ・幅・アスペクト比が異なるアンカーボックスを用意する  \n",
    "特徴量マップ上のスライディングウインドウ毎にアンカーボックスを当てはめ、正解ラベルと一致率が高いものを１、それ以外を０に割り振る  \n",
    "その座標を損失関数として、損失が小さくなるように学習する  \n",
    "学習したパラメータを元に物体の領域を提案する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) RoIプーリングとは何か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考論文  \n",
    "Fast R-CNN  \n",
    "\n",
    "論文箇所  \n",
    "3 FASTER R-CNN  \n",
    "3.2 Sharing Features for RPN and Fast R-CNN  \n",
    "\n",
    "The RoI pooling layer [2] in Fast R-CNN accepts the convolutional features and also the predicted bounding boxes as input,  \n",
    "\n",
    "畳み込みした特徴量マップと予測領域を入力として受け取る  \n",
    "提案された領域の中でmaxpoolingを行う  \n",
    "出力スケールは固定されていて、全てそのサイズにスケーリングする  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   (6) Anchorのサイズはどうするのが適切か。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "論文箇所  \n",
    "4 EXPERIMENTS  \n",
    "4.1 Experiments on PASCAL VOC  \n",
    "\n",
    "Table 8  \n",
    "settings             anchor scales                    spect ratios              mAP  \n",
    "1 scale, 1 ratio     128^2                             1:1                      65.8  \n",
    "                       \n",
    "1 scale, 3 ratios   128^2                             {2:1, 1:1, 1:2}         68.8   \n",
    "\n",
    "3 scales, 1 ratio  {128^2,256^2,512^2}        1:1                      69.8  \n",
    "\n",
    "3 scales, 3 ratios {128^2,256^2,512^2}   {2:1, 1:1, 1:2}            69.9  \n",
    "\n",
    "**3スケールの3ratioだとmAPは69.9  \n",
    "３スケールの1ratioだとmAPは69.8**  \n",
    "\n",
    "**3スケールの3ratioか3スケールの1ratioが良い**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 何というデータセットを使い、先行研究に比べどういった指標値が得られているか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "論文箇所  \n",
    "4 EXPERIMENTS  \n",
    "\n",
    "使用したデータセット  \n",
    "PASCAL VOC 2007  \n",
    "PASCAL VOC 2012  \n",
    "Microsoft COCO object detection dataset  \n",
    "\n",
    "比較  \n",
    "Fast    R-CNN  mAP:35.9    \n",
    "Faster R-CNN  mAP:42.7  \n",
    "\n",
    "先行研究に比べ高いmAPを得られている    \n",
    "また、計算速度も早い    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
