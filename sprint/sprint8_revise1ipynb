{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint アンサンブル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"/Users/morishuuya/Desktop/dataset/kaggle/HousePrice/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "t = train_data.loc[:, \"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】ブレンディングのスクラッチ実装\n",
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1回目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "dt = DecisionTreeRegressor()\n",
    "svr = SVR(gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, t_train)\n",
    "dt.fit(X_train, t_train)\n",
    "svr.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr = lr.predict(X_test)\n",
    "y_dt = dt.predict(X_test)\n",
    "y_svr = svr.predict(X_test)\n",
    "blending_1 = (y_lr + y_dt + y_svr) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      " 2561363471.90957\n",
      "DecisionTree\n",
      " 2945653447.2063355\n",
      "SVR\n",
      " 7407184312.81181\n",
      "Blend\n",
      " 2579522278.771746\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression\\n\",mean_squared_error(t_test, y_lr))\n",
    "print(\"DecisionTree\\n\", mean_squared_error(t_test, y_dt))\n",
    "print(\"SVR\\n\", mean_squared_error(t_test, y_svr))\n",
    "print(\"Blend\\n\",mean_squared_error(t_test, blending_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2回目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LinearRegression(normalize = True)\n",
    "dt2 = DecisionTreeRegressor(max_depth=5)\n",
    "svr2 = SVR(gamma=\"scale\", kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2.fit(X_train, t_train)\n",
    "dt2.fit(X_train, t_train)\n",
    "svr2.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr2 = lr2.predict(X_test)\n",
    "y_dt2 = dt2.predict(X_test)\n",
    "y_svr2 = svr2.predict(X_test)\n",
    "blending_2 = ((y_lr2) + (y_dt2) + (y_svr2)) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2561363471.9095693\n",
      "2141235228.9211636\n",
      "2588348328.6793923\n",
      "2291204529.8539367\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(t_test, y_lr2))\n",
    "print(mean_squared_error(t_test, y_dt2))\n",
    "print(mean_squared_error(t_test, y_svr2))\n",
    "print(mean_squared_error(t_test, blending_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3回目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/morishuuya/.pyenv/versions/anaconda3-2019.03/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3_sc = LinearRegression()\n",
    "dt3_sc = DecisionTreeRegressor(max_depth=3)\n",
    "svr3_sc = SVR(gamma=\"scale\", kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3 = LinearRegression()\n",
    "dt3 = DecisionTreeRegressor(max_depth=3)\n",
    "svr3 = SVR(gamma=\"scale\", kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr3_sc.fit(X_train_sc, t_train)\n",
    "dt3_sc.fit(X_train_sc, t_train)\n",
    "svr3_sc.fit(X_train_sc, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr3.fit(X_train, t_train)\n",
    "dt3.fit(X_train, t_train)\n",
    "svr3.fit(X_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lr3_sc = lr3_sc.predict(X_test) \n",
    "y_dt3_sc = dt3_sc.predict(X_test) \n",
    "y_svr3_sc = svr3_sc.predict(X_test)\n",
    "\n",
    "blending_3 = ((y_lr3_sc*0.0001) + (y_dt3_sc*0.9) + (y_svr3_sc*0.0009)) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0457844510081444e+16\n",
      "42345536250.3215\n",
      "5533269334162.9795\n",
      "11416854524.569424\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(t_test, y_lr3_sc))\n",
    "print(mean_squared_error(t_test, y_dt3_sc))\n",
    "print(mean_squared_error(t_test, y_svr3_sc))\n",
    "\n",
    "print(mean_squared_error(t_test, blending_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】バギングのスクラッチ実装\n",
    "バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datasplit:\n",
    "    \"\"\"\n",
    "    データを上から分割し、リストに格納するクラス\n",
    "    最後は余りを含めているので、最後だけ数が異なる可能性がある\n",
    "    \"\"\"\n",
    "    def __init__(self, split_num):\n",
    "        # 分割数を入力\n",
    "        self.split_num = split_num\n",
    "        \n",
    "    def X(self, data):\n",
    "        split_point =  int(np.round(data.shape[0]/self.split_num))\n",
    "        data_list = []\n",
    "        j = 1\n",
    "        for i in range(self.split_num):\n",
    "            if i ==(self.split_num-1):\n",
    "                data_list.append(data[split_point*i:, :])\n",
    "            else:\n",
    "                data_list.append(data[split_point*i:split_point*j, :])\n",
    "                j+= 1\n",
    "        return data_list\n",
    "    \n",
    "    def t(self, data):\n",
    "        split_point =  int(np.round(data.shape[0]/self.split_num))\n",
    "        data_list = []\n",
    "        j = 1\n",
    "        for i in range(self.split_num):\n",
    "            if i ==(self.split_num-1):\n",
    "                data_list.append(data[split_point*i:])\n",
    "            else:\n",
    "                data_list.append(data[split_point*i:split_point*j])\n",
    "                j+= 1\n",
    "        return data_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_list(model, num):\n",
    "    \"\"\"\n",
    "    入力されたモデルを格納したリストを返す\n",
    "    \"\"\"\n",
    "    model_list = []\n",
    "    for i in range(num):\n",
    "        model_list.append(model)\n",
    "        \n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_b, X_test_b, t_train_b, t_test_b = train_test_split(X, t, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_baggin = datasplit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xのデータを分割\n",
    "X_baggin_list = ds_baggin.X(X_train_b.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tのデータを分割\n",
    "t_bagging_list = ds_baggin.t(t_train_b.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルを作成\n",
    "bagging_model_list = make_model_list( DecisionTreeRegressor(max_depth=5), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_pred_list = []\n",
    "for i in range(4):\n",
    "    bagging_model_list[i].fit(X_baggin_list[i], t_bagging_list[i])\n",
    "    bagging_pred_list.append(bagging_model_list[i].predict(X_test_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "baging_1 = (bagging_pred_list[0]+bagging_pred_list[1]+bagging_pred_list[2]+bagging_pred_list[3]) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1923088782.7716286\n",
      "3738272611.348503\n",
      "5777680571.288019\n",
      "1879587226.7646046\n",
      "1884330742.2319853\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(t_test_b, bagging_pred_list[0]))\n",
    "print(mean_squared_error(t_test_b, bagging_pred_list[1]))\n",
    "print(mean_squared_error(t_test_b,bagging_pred_list[2]))\n",
    "print(mean_squared_error(t_test_b, bagging_pred_list[3]))\n",
    "\n",
    "print(mean_squared_error(t_test_b, baging_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】スタッキングのスクラッチ実装\n",
    "スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス、関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataconcate(data_list):\n",
    "    \"\"\"\n",
    "    分割されたデータのリスト受け取り、それぞれ組み合わせたデータを返す\n",
    "    \"\"\"\n",
    "    dataset_list = []\n",
    "    for i in range(len(data_list)):\n",
    "        for j in range(len(data_list)):\n",
    "            if i==j or i>j:\n",
    "                pass\n",
    "            else:\n",
    "                dataset_list.append(np.concatenate([data_list[i], data_list[j]], axis=0))\n",
    "    return dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model_list, X_list, X_dataset, t_dataset):\n",
    "    \"\"\"\n",
    "    データの組み合わせごとに学習および、推定を行う\n",
    "    学習後のモデルと推定値のリストを返す\n",
    "    \"\"\"\n",
    "    predict_list = []\n",
    "    for i in range(len(model_list)):\n",
    "        model_list[i].fit(X_dataset[i], t_dataset[i])\n",
    "        predict_list.append(model_list[i].predict(X_list[-i]))\n",
    "    return model_list, predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_list, X_test):\n",
    "    \"\"\"\n",
    "    モデルのリストを受け取り、テストデータで推定し、推定値のリストを返す\n",
    "    \"\"\"\n",
    "    predict_list = []\n",
    "    for i in range(len(model_list)):\n",
    "        predict_list.append(model_list[i].predict(X_test))\n",
    "    return predict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データを分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasplit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = ds.X(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_list= ds.t(t_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割データの組み合わせ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = dataconcate(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dataset = dataconcate(t_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  モデルのリストを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML1_DT = make_model_list( DecisionTreeRegressor(max_depth=5), 3)\n",
    "ML2_DT =make_model_list( DecisionTreeRegressor(max_depth=5), 3)\n",
    "ML1_SVR = make_model_list(SVR(gamma=\"scale\"), 3)\n",
    "ML2_SVR = make_model_list(SVR(gamma=\"scale\"), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最初の学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML1_DT, predict1_DT = training(ML1_DT, X_list, X_dataset, t_dataset)\n",
    "ML1_SVR, predict1_SVR = training(ML1_SVR, X_list, X_dataset, t_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最初のブレンドデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_data_DT = np.concatenate([predict1_DT[0], predict1_DT[1], predict1_DT[2]])\n",
    "blend_data_SVR = np.concatenate([predict1_SVR[0], predict1_SVR[1], predict1_SVR[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_data_1 = np.stack([blend_data_DT , blend_data_SVR], 1)\n",
    "blend_data_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ブレンドデータの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasplit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = ds.X(blend_data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割データの組み合わせ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = dataconcate(X_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2回目の学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML2_DT, predict2_DT = training(ML2_DT, X_list, X_dataset, t_dataset)\n",
    "ML2_SVR, predict2_SVR = training(ML2_SVR, X_list, X_dataset, t_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二つ目のブレンドデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_data_DT = np.concatenate([predict2_DT[0], predict2_DT[1], predict2_DT[2]])\n",
    "blend_data_SVR = np.concatenate([predict2_SVR[0], predict2_SVR[1], predict2_SVR[2]])\n",
    "blend_data_2 = np.stack([blend_data_DT , blend_data_SVR], 1)\n",
    "blend_data_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最後の学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_SVR = SVR(gamma=\"scale\")\n",
    "last_SVR.fit(blend_data_2, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最初の推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_DT1 = predict(ML1_DT, X_test.values)\n",
    "pred_SVR1 = predict(ML1_SVR , X_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最初のブレンドデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_test_DT1 = np.stack([pred_DT1[0], pred_DT1[1], pred_DT1[2]], 1)\n",
    "blend_test_SVR1 = np.stack([pred_SVR1[0], pred_SVR1[1], pred_SVR1[2]], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_test_DT1 = np.average(blend_test_DT1 , 1)\n",
    "blend_test_SVR1 = np.average(blend_test_SVR1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_test1 = np.stack([blend_test_DT1, blend_test_SVR1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2回目の推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_DT2 = predict(ML2_DT, blend_test1)\n",
    "pred_SVR2 = predict(ML2_SVR, blend_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二つ目のブレンドデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_test_DT2 = np.stack([pred_DT2[0], pred_DT2[1], pred_DT2[2]], 1)\n",
    "blend_test_SVR2 = np.stack([pred_SVR2[0], pred_SVR2[1], pred_SVR2[2]], 1)\n",
    "blend_test_DT2 = np.average(blend_test_DT2 , 1)\n",
    "blend_test_SVR2 = np.average(blend_test_SVR2, 1)\n",
    "blend_test2 = np.stack([blend_test_DT2, blend_test_SVR2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最後の推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = last_SVR.predict(blend_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7418121257.329934\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(t_test, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
