{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 深層学習スクラッチ 畳み込みニューラルネットワーク1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ、クラスの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        layer.W = layer.W -  self.lr * layer.LW\n",
    "        \n",
    "        layer.B = layer.B - self.lr*layer.LB\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, w, b , optimizer,stride, padding):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        #init = initializer\n",
    "        #self.W = init.W(num_filter)\n",
    "        #self.B = init.B(num_bias)\n",
    "        self.W = w\n",
    "        self.B = b\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.A = X\n",
    "        a = np.zeros(len(X)-2)\n",
    "        for i in range(len(X) - 2):\n",
    "            sig = 0\n",
    "            for j in range(len(self.W)):\n",
    "                sig += X[i+j] * self.W[j]\n",
    "            sig += self.B\n",
    "            a[i] = sig\n",
    "\n",
    "        \n",
    "        return a\n",
    "\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        n_out = N_OUT(self.stride, self.padding, self.A, self.W)\n",
    "\n",
    "        self.LB = np.sum(dA)\n",
    "        \n",
    "        #LWの計算\n",
    "        self.LW = np.zeros_like(self.W)\n",
    "        for s in range(len(self.W)):\n",
    "            sigma = 0\n",
    "            for i in range(len(self.W)-1):\n",
    "                sigma += dA[i] * self.A[i+s]\n",
    "            self.LW[s] = sigma\n",
    "        \n",
    "        #dZの計算\n",
    "        self.dZ = np.zeros_like(self.A)\n",
    "        for j in range(len(self.A)):\n",
    "            sigma = 0\n",
    "            for s in range(len(self.W)):\n",
    "                if j - s < 0 or j - s > n_out-1:\n",
    "                    pass\n",
    "                else:\n",
    "                    sigma += dA[j-s] * self.W[s]\n",
    "            self.dZ[j] = sigma\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return self.dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】1次元畳み込み後の出力サイズの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def N_OUT(stride, padding, X,  W):\n",
    "    if X.ndim == 1:\n",
    "        return int((X.shape[0] + (2*padding) - len(W) / stride) + 1)\n",
    "    elif X.ndim == 3:\n",
    "        return int((X.shape[2] + (2*padding) - len(W) / stride) + 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】小さな配列での1次元畳み込み層の実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35. 50.]\n",
      "[ 30 110 170 140]\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN_FC(w, b, SGD(0.1), 1, 0)\n",
    "print(cnn.forward(x))\n",
    "print(cnn.backward(delta_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "w = np.ones((3, 2, 3))\n",
    "b = np.array([1, 2, 3])\n",
    "delta_a2 = np.array([[52, 56], [32, 35], [9, 11]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2dim_FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, w, b , optimizer,stride, padding):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        #init = initializer\n",
    "        #self.W = init.W(num_filter)\n",
    "        #self.B = init.B(num_bias)\n",
    "        self.W = w\n",
    "        self.B = b\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.A = X\n",
    "        output_size, chanel_size, filter_size = self.W.shape\n",
    "        feature_size = self.A.shape[1]\n",
    "\n",
    "        a = np.zeros([output_size, feature_size - 2])\n",
    "        for output in range(output_size):\n",
    "            for j in range(filter_size - 1):\n",
    "                sig = 0\n",
    "                for chanel in range(chanel_size):\n",
    "                    for i in range(filter_size):\n",
    "                        sig += X[chanel, i+j] * self.W[output, chanel, j]\n",
    "                a[output, j] = sig + b[output]\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "        \n",
    "        return a\n",
    "\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.n_out = N_OUT(self.stride, self.padding, self.W, self.A)\n",
    "        self.LB = np.sum(dA, axis=1)\n",
    "        \n",
    "        output_size, chanel_size, filter_size = self.W.shape\n",
    "        feature_size = self.A.shape[1]\n",
    "        \n",
    "        #LWの計算\n",
    "        self.LW = np.zeros_like(self.W)\n",
    "        for output in range(output_size):\n",
    "            for chanel in range(chanel_size):\n",
    "                for i in range(filter_size):\n",
    "                    for j in range(filter_size -1):\n",
    "                        self.LW[output, chanel, i] += dA[output, j]*self.A[chanel, j+i]\n",
    "\n",
    "                    \n",
    "                    \n",
    "        \n",
    "        #dZの計算\n",
    "        dZ = np.zeros_like(self.A)\n",
    "        for output in range(output_size):\n",
    "            for chanel in range(chanel_size):\n",
    "                for j in range(feature_size):\n",
    "                    sigma=0\n",
    "                    for s in range(filter_size):\n",
    "                        if j - s < 0 or j - s > self.n_out -1:\n",
    "                            pass\n",
    "                        else:\n",
    "                            sigma += dA[output,  j-s] * self.W[output, chanel, s]\n",
    "                    dZ[chanel, j] += sigma\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二次元　実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16. 22.]\n",
      " [17. 23.]\n",
      " [18. 24.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 93, 195, 195, 102],\n",
       "       [ 93, 195, 195, 102]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_2 = CNN2dim_FC(w, b, SGD(0.1), 1, 0)\n",
    "print(cnn_2.forward(x))\n",
    "cnn_2.backward(delta_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "(X_train, t_train), (X_test, t_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "t_train_one_hot = enc.fit_transform(t_train[:, np.newaxis])\n",
    "t_test_one_hot = enc.fit_transform(t_test[:,  np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 1, 784)\n",
    "X_test = X_test.reshape(-1, 1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.ones((3, 1, 3))\n",
    "b = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_mnist_FC:\n",
    "    \"\"\"\n",
    "    畳み込み層\n",
    "    Parameters\n",
    "    ----------\n",
    "    w:畳み込み層の重み　w.shape  (出力チャネル、入力チャネル、フィルターサイズ)\n",
    "    b:畳み込み層のバイアス　b.shape (出力チャネル, )\n",
    "    stride:ストライド数\n",
    "    padding:パディング数\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, w, b , optimizer,stride, padding):\n",
    "        self.optimizer = optimizer\n",
    "        self.W = w\n",
    "        self.B = b\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.A = X\n",
    "        output_size, chanel_size, filter_size = self.W.shape\n",
    "        feature_size = self.A.shape[2]\n",
    "        sample_size = self.A.shape[0]\n",
    "\n",
    "        a = np.zeros([sample_size, output_size, feature_size-2])\n",
    "        for samples in range(sample_size):\n",
    "            for output in range(output_size):\n",
    "                for j in range(filter_size - 1):\n",
    "                    sig = 0\n",
    "                    for chanel in range(chanel_size):\n",
    "                        for i in range(filter_size):\n",
    "                            sig += X[samples, chanel, i+j] * self.W[output, chanel, j]\n",
    "                    a[samples, output, j] = sig + b[output]\n",
    "        \n",
    "        return a\n",
    "\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.n_out = N_OUT(self.stride, self.padding, self.W, self.A)\n",
    "        \n",
    "        output_size, chanel_size, filter_size = self.W.shape\n",
    "        feature_size = self.A.shape[2]\n",
    "        sample_size = self.A.shape[0]\n",
    "        \n",
    "        #LBの計算\n",
    "        self.LB = dA.sum(axis=0)\n",
    "        self.LB = self.LB.sum(axis=1)\n",
    "        \n",
    "        #LWの計算\n",
    "        self.LW = np.zeros_like(self.W)\n",
    "        for samples in range(sample_size):\n",
    "            for output in range(output_size):\n",
    "                for chanel in range(chanel_size):\n",
    "                    for i in range(filter_size):\n",
    "                        for j in range(filter_size -1):\n",
    "                            self.LW[output, chanel, i] += dA[samples, output, j]*self.A[samples, chanel, j+i]\n",
    "                        \n",
    "                        \n",
    "\n",
    "                    \n",
    "                    \n",
    "        #dZの計算\n",
    "        dZ = np.zeros_like(self.A)\n",
    "        for samples in range(sample_size):\n",
    "            for output in range(output_size):\n",
    "                for chanel in range(chanel_size):\n",
    "                    for j in range(feature_size):\n",
    "                        sigma=0\n",
    "                        for s in range(filter_size):\n",
    "                            if j - s < 0 or j - s > self.n_out -1:\n",
    "                                pass\n",
    "                            else:\n",
    "                                sigma += dA[samples, output,  j-s] * self.W[output, chanel, s]\n",
    "                        dZ[samples, chanel, j] += sigma\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def forward(self, X):\n",
    "        self.A = X\n",
    "        return np.maximum(0, X)\n",
    "    \n",
    "    def backward(self, Z):\n",
    "        \n",
    "        return Z * np.maximum(np.sign(self.A), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        init = initializer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.W = init.W(n_nodes1, n_nodes2)\n",
    "        self.B = init.B(n_nodes2)\n",
    "    \n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.z = X\n",
    "        self.a = X@self.W + self.B\n",
    "        \n",
    "        return self.a\n",
    "\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dZ = dA @ self.W.T\n",
    "        self.LW = self.z.T @ dA\n",
    "        self.LB = np.sum(dA, axis=0)\n",
    "        \n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B  = self.sigma * np.random.randn(n_nodes2)\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def forward(self, A):\n",
    "        exp_a = np.exp(A)\n",
    "        softmax_result = np.empty((A.shape[0], A.shape[1]))\n",
    "        exp_sum = np.sum(exp_a, axis=1)\n",
    "        for i in range(A.shape[0]):\n",
    "            softmax_result[i] = exp_a[i] / exp_sum[i]\n",
    "            \n",
    "        return softmax_result\n",
    "    \n",
    "    def backward(self, Z, Y):\n",
    "        \n",
    "        L_A = Z - Y\n",
    "        self.cross_entropy = -np.average(np.sum(Y*np.log(Z), axis=1))\n",
    "        \n",
    "        \n",
    "        return L_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mnist = CNN_mnist_FC(w, b, SGD(0.1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = cnn_mnist.forward(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = Relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_relu = relu.forward(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_flat = A_relu.reshape(A_relu.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_1 = FC(2346, 10, SimpleInitializer(0.1), SGD(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_FC_1 = FC_1.forward(A_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_soft = softmax.forward(A_FC_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_delta = softmax.backward(A_soft, t_train_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_Z = FC_1.backward(A_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_Z_reshape = delta_Z.reshape(A_relu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_Z_relu = relu.backward(delta_Z_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dZ = cnn_mnist.backward(delta_Z_relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1, 1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_A = cnn_mnist.forward(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_A = relu.forward(t_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_A  = t_A.reshape(t_A.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_A = FC_1.forward(t_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.max(t_A, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(t_A.shape[0]):\n",
    "    t_A[i] = np.exp(t_A[i] - C[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_A = softmax.forward(t_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(t_A, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0892\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(t_test, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
